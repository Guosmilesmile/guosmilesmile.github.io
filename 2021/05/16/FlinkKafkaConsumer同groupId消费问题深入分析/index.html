<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.1">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.1">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.1" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.0.1',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="问题这有两个相同代码的程序： 12345678910val bsEnv = StreamExecutionEnvironment.getExecutionEnvironment Env.setRestartStrategy(RestartStrategies.noRestart()) val consumerProps = new Properties() consumerProps.put(&quot;b">
<meta property="og:type" content="article">
<meta property="og:title" content="FlinkKafkaConsumer同groupId消费问题深入分析">
<meta property="og:url" content="http://yoursite.com/2021/05/16/FlinkKafkaConsumer同groupId消费问题深入分析/index.html">
<meta property="og:site_name" content="Pray">
<meta property="og:description" content="问题这有两个相同代码的程序： 12345678910val bsEnv = StreamExecutionEnvironment.getExecutionEnvironment Env.setRestartStrategy(RestartStrategies.noRestart()) val consumerProps = new Properties() consumerProps.put(&quot;b">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2021-05-16T06:36:59.948Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="FlinkKafkaConsumer同groupId消费问题深入分析">
<meta name="twitter:description" content="问题这有两个相同代码的程序： 12345678910val bsEnv = StreamExecutionEnvironment.getExecutionEnvironment Env.setRestartStrategy(RestartStrategies.noRestart()) val consumerProps = new Properties() consumerProps.put(&quot;b">






  <link rel="canonical" href="http://yoursite.com/2021/05/16/FlinkKafkaConsumer同groupId消费问题深入分析/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>FlinkKafkaConsumer同groupId消费问题深入分析 | Pray</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Pray</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">人肉排渣工程师,擅长排渣数据，服务器排渣</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/05/16/FlinkKafkaConsumer同groupId消费问题深入分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="笑笑">
      <meta itemprop="description" content>
      <meta itemprop="image" content="https://note.youdao.com/yws/api/personal/file/85E1A31B078749AAA5FBFA9FF57A0FCB?method=download&shareKey=312d566957926c021bfd2bf29d0fb19c#/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Pray">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">FlinkKafkaConsumer同groupId消费问题深入分析

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2021-05-16 14:25:56 / 修改时间：14:36:59" itemprop="dateCreated datePublished" datetime="2021-05-16T14:25:56+08:00">2021-05-16</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Flink/" itemprop="url" rel="index"><span itemprop="name">Flink</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon">
            <i class="fa fa-eye"></i>
             阅读次数： 
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>这有两个相同代码的程序：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">val bsEnv = StreamExecutionEnvironment.getExecutionEnvironment</span><br><span class="line"> Env.setRestartStrategy(RestartStrategies.noRestart())</span><br><span class="line"> val consumerProps = <span class="keyword">new</span> Properties()</span><br><span class="line"> consumerProps.put(<span class="string">"bootstrap.servers"</span>, brokers)</span><br><span class="line"> consumerProps.put(<span class="string">"group.id"</span>, <span class="string">"test1234"</span>)</span><br><span class="line"></span><br><span class="line"> val consumer = <span class="keyword">new</span> FlinkKafkaConsumer[String](topic,<span class="keyword">new</span> KafkaStringSchema,consumerProps).setStartFromLatest()</span><br><span class="line"> Env.addSource(consumer).print()</span><br><span class="line"> Env.execute()</span><br></pre></td></tr></table></figure>
<p>同时启动这两个程序，他们连接相同的集群的topic，group.id也一样，然后向topic发送一些数据，发现这两个程序都能消费到发送的所有分区的消息，kafka 的consumer group组内应该是有消费隔离的，为什么这里两个程序都能同时消费到全部数据呢?</p>
<p>而用KafkaConsumer写两个相同的程序去消费这个topic就可以看到两边程序是没有重复消费同一分区的</p>
<h3 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h3><p>在 Flink 消费 Kafka 的过程中， 由 FlinkKafkaConsumer 会从 Kafka 中拿到当前 topic 的所有 partition 信息并分配并发消费，这里的 group id 只是用于将当前 partition 的消费 offset commit 到 Kafka，并用这个消费组标识。而使用 KafkaConsumer 消费数据则应用到了 Kafka 的消费组管理, 这是 Kafka 服务端的一个角色。</p>
<p>为了保证 Flink 程序的 exactly-once，必须由各个 Kafka source  算子维护当前算子所消费的 partition 消费 offset 信息，并在每次checkpoint 时将这些信息写入到 state 中， 在从 checkpoint 恢复中从上次 commit 的位点开始消费，保证 exactly-once.  如果用 Kafka 消费组管理，那么 FlinkKafkaConsumer 内各个并发实例所分配的 partition 将由 Kafka 的消费组管理，且 offset 也由 Kafka 消费组管理者记录，Flink 无法维护这些信息。</p>
<h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p>，当启动两个作业用同一个 topic 和 group id 消费 kafka， 如果两个作业会分别以同一个 group id commit offset 到kafka， 如果以 group offset 消费模式启动作业， 则会以最后一次 commit 的 offset 开始消费。</p>
<h3 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h3><p>先看下社区的分析：</p>
<p><a href="http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/Flink-kafka-group-question-td8185.html#none" target="_blank" rel="noopener">http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/Flink-kafka-group-question-td8185.html#none</a></p>
<p>Internally, the Flink Kafka connectors don’t use the consumer group management functionality because they are using lower-level APIs (SimpleConsumer in 0.8, and KafkaConsumer#assign(…) in 0.9) on each parallel instance for more control on individual partition consumption. So, essentially, the “group.id” setting in the Flink Kafka connector is only used for committing offsets back to ZK / Kafka brokers.</p>
<p>flink的版本没有用到group id这个属性。。</p>
<p>初步结论<br><a href="https://issues.apache.org/jira/browse/FLINK-11325" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/FLINK-11325</a></p>
<p>connecter消费数据的时候，使用 ./bin/kafka-consumer-groups.sh就是无法获取 CONSUMER-ID HOST CLIENT-ID等值。因为Flink实现connecter的时候，就没有使用到kafka的这个feature。此时我们需要通过Flink的metric可以看到消费情况。</p>
<p>进一步看源码吧：</p>
<h3 id="KafkaConsumer实现"><a href="#KafkaConsumer实现" class="headerlink" title="KafkaConsumer实现"></a>KafkaConsumer实现</h3><p>我们使用kafka-client的时候，一般使用KafkaConsumer构建我们的消费实例，使用poll来获取数据:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">KafkaConsumer&lt;Integer, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">……</span><br><span class="line">ConsumerRecords&lt;Integer, String&gt; records = consumer.poll();</span><br></pre></td></tr></table></figure>
<p>我们看下org.apache.kafka.clients.consumer.KafkaConsumer核心部分</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="title">KafkaConsumer</span><span class="params">(ConsumerConfig config, Deserializer&lt;K&gt; keyDeserializer, Deserializer&lt;V&gt; valueDeserializer)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">           String clientId = config.getString(ConsumerConfig.CLIENT_ID_CONFIG);</span><br><span class="line">           <span class="keyword">if</span> (clientId.isEmpty()) <span class="comment">// </span></span><br><span class="line">               clientId = <span class="string">"consumer-"</span> + CONSUMER_CLIENT_ID_SEQUENCE.getAndIncrement();</span><br><span class="line">           <span class="keyword">this</span>.clientId = clientId;</span><br><span class="line">           <span class="keyword">this</span>.groupId = config.getString(ConsumerConfig.GROUP_ID_CONFIG);</span><br><span class="line">           LogContext logContext = <span class="keyword">new</span> LogContext(<span class="string">"[Consumer clientId="</span> + clientId + <span class="string">", groupId="</span> + groupId + <span class="string">"] "</span>);</span><br><span class="line">           <span class="keyword">this</span>.log = logContext.logger(getClass());</span><br><span class="line">           <span class="keyword">boolean</span> enableAutoCommit = config.getBoolean(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG);</span><br><span class="line">           <span class="keyword">if</span> (groupId == <span class="keyword">null</span>) &#123; <span class="comment">// 未指定groupId的情况下，不能设置”自动提交offset“</span></span><br><span class="line">               <span class="keyword">if</span> (!config.originals().containsKey(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG))</span><br><span class="line">                   enableAutoCommit = <span class="keyword">false</span>;</span><br><span class="line">               <span class="keyword">else</span> <span class="keyword">if</span> (enableAutoCommit)</span><br><span class="line">                   <span class="keyword">throw</span> <span class="keyword">new</span> InvalidConfigurationException(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG + <span class="string">" cannot be set to true when default group id (null) is used."</span>);</span><br><span class="line">           &#125; <span class="keyword">else</span> <span class="keyword">if</span> (groupId.isEmpty())</span><br><span class="line">               log.warn(<span class="string">"Support for using the empty group id by consumers is deprecated and will be removed in the next major release."</span>);</span><br><span class="line"></span><br><span class="line">           log.debug(<span class="string">"Initializing the Kafka consumer"</span>);</span><br><span class="line">           <span class="keyword">this</span>.requestTimeoutMs = config.getInt(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG);</span><br><span class="line">           <span class="keyword">this</span>.defaultApiTimeoutMs = config.getInt(ConsumerConfig.DEFAULT_API_TIMEOUT_MS_CONFIG);</span><br><span class="line">           <span class="keyword">this</span>.time = Time.SYSTEM;</span><br><span class="line"></span><br><span class="line">           Map&lt;String, String&gt; metricsTags = Collections.singletonMap(<span class="string">"client-id"</span>, clientId);</span><br><span class="line">           MetricConfig metricConfig = <span class="keyword">new</span> MetricConfig().samples(config.getInt(ConsumerConfig.METRICS_NUM_SAMPLES_CONFIG))</span><br><span class="line">                   .timeWindow(config.getLong(ConsumerConfig.METRICS_SAMPLE_WINDOW_MS_CONFIG), TimeUnit.MILLISECONDS)</span><br><span class="line">                   .recordLevel(Sensor.RecordingLevel.forName(config.getString(ConsumerConfig.METRICS_RECORDING_LEVEL_CONFIG)))</span><br><span class="line">                   .tags(metricsTags);</span><br><span class="line">           List&lt;MetricsReporter&gt; reporters = config.getConfiguredInstances(ConsumerConfig.METRIC_REPORTER_CLASSES_CONFIG,</span><br><span class="line">                   MetricsReporter.class, Collections.singletonMap(ConsumerConfig.CLIENT_ID_CONFIG, clientId));</span><br><span class="line">           reporters.add(<span class="keyword">new</span> JmxReporter(JMX_PREFIX));</span><br><span class="line">           <span class="keyword">this</span>.metrics = <span class="keyword">new</span> Metrics(metricConfig, reporters, time);</span><br><span class="line">           <span class="keyword">this</span>.retryBackoffMs = config.getLong(ConsumerConfig.RETRY_BACKOFF_MS_CONFIG);</span><br><span class="line"></span><br><span class="line">           <span class="comment">// load interceptors and make sure they get clientId</span></span><br><span class="line">           Map&lt;String, Object&gt; userProvidedConfigs = config.originals();</span><br><span class="line">           userProvidedConfigs.put(ConsumerConfig.CLIENT_ID_CONFIG, clientId);</span><br><span class="line">           List&lt;ConsumerInterceptor&lt;K, V&gt;&gt; interceptorList = (List) (<span class="keyword">new</span> ConsumerConfig(userProvidedConfigs, <span class="keyword">false</span>)).getConfiguredInstances(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG,</span><br><span class="line">                   ConsumerInterceptor.class);</span><br><span class="line">           <span class="keyword">this</span>.interceptors = <span class="keyword">new</span> ConsumerInterceptors&lt;&gt;(interceptorList);</span><br><span class="line">           <span class="keyword">if</span> (keyDeserializer == <span class="keyword">null</span>) &#123;</span><br><span class="line">               <span class="keyword">this</span>.keyDeserializer = config.getConfiguredInstance(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, Deserializer.class);</span><br><span class="line">               <span class="keyword">this</span>.keyDeserializer.configure(config.originals(), <span class="keyword">true</span>);</span><br><span class="line">           &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">               config.ignore(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG);</span><br><span class="line">               <span class="keyword">this</span>.keyDeserializer = keyDeserializer;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">if</span> (valueDeserializer == <span class="keyword">null</span>) &#123;</span><br><span class="line">               <span class="keyword">this</span>.valueDeserializer = config.getConfiguredInstance(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, Deserializer.class);</span><br><span class="line">               <span class="keyword">this</span>.valueDeserializer.configure(config.originals(), <span class="keyword">false</span>);</span><br><span class="line">           &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">               config.ignore(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG);</span><br><span class="line">               <span class="keyword">this</span>.valueDeserializer = valueDeserializer;</span><br><span class="line">           &#125;</span><br><span class="line">           ClusterResourceListeners clusterResourceListeners = configureClusterResourceListeners(keyDeserializer, valueDeserializer, reporters, interceptorList);</span><br><span class="line">           <span class="keyword">this</span>.metadata = <span class="keyword">new</span> Metadata(retryBackoffMs, config.getLong(ConsumerConfig.METADATA_MAX_AGE_CONFIG),</span><br><span class="line">                   <span class="keyword">true</span>, <span class="keyword">false</span>, clusterResourceListeners); </span><br><span class="line">           List&lt;InetSocketAddress&gt; addresses = ClientUtils.parseAndValidateAddresses(</span><br><span class="line">                   config.getList(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG), config.getString(ConsumerConfig.CLIENT_DNS_LOOKUP_CONFIG));</span><br><span class="line">           <span class="keyword">this</span>.metadata.bootstrap(addresses, time.milliseconds());</span><br><span class="line">           String metricGrpPrefix = <span class="string">"consumer"</span>;</span><br><span class="line">           ConsumerMetrics metricsRegistry = <span class="keyword">new</span> ConsumerMetrics(metricsTags.keySet(), <span class="string">"consumer"</span>);</span><br><span class="line">           ChannelBuilder channelBuilder = ClientUtils.createChannelBuilder(config, time);</span><br><span class="line">           IsolationLevel isolationLevel = IsolationLevel.valueOf(</span><br><span class="line">                   config.getString(ConsumerConfig.ISOLATION_LEVEL_CONFIG).toUpperCase(Locale.ROOT));</span><br><span class="line">           Sensor throttleTimeSensor = Fetcher.throttleTimeSensor(metrics, metricsRegistry.fetcherMetrics);</span><br><span class="line">           <span class="keyword">int</span> heartbeatIntervalMs = config.getInt(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG);</span><br><span class="line"></span><br><span class="line">           NetworkClient netClient = <span class="keyword">new</span> NetworkClient(</span><br><span class="line">                   <span class="keyword">new</span> Selector(config.getLong(ConsumerConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG), metrics, time, metricGrpPrefix, channelBuilder, logContext),</span><br><span class="line">                   <span class="keyword">this</span>.metadata,</span><br><span class="line">                   clientId,</span><br><span class="line">                   <span class="number">100</span>, <span class="comment">// a fixed large enough value will suffice for max in-flight requests</span></span><br><span class="line">                   config.getLong(ConsumerConfig.RECONNECT_BACKOFF_MS_CONFIG),</span><br><span class="line">                   config.getLong(ConsumerConfig.RECONNECT_BACKOFF_MAX_MS_CONFIG),</span><br><span class="line">                   config.getInt(ConsumerConfig.SEND_BUFFER_CONFIG),</span><br><span class="line">                   config.getInt(ConsumerConfig.RECEIVE_BUFFER_CONFIG),</span><br><span class="line">                   config.getInt(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG),</span><br><span class="line">                   ClientDnsLookup.forConfig(config.getString(ConsumerConfig.CLIENT_DNS_LOOKUP_CONFIG)),</span><br><span class="line">                   time,</span><br><span class="line">                   <span class="keyword">true</span>,</span><br><span class="line">                   <span class="keyword">new</span> ApiVersions(),</span><br><span class="line">                   throttleTimeSensor,</span><br><span class="line">                   logContext);</span><br><span class="line">           <span class="keyword">this</span>.client = <span class="keyword">new</span> ConsumerNetworkClient(</span><br><span class="line">                   logContext,</span><br><span class="line">                   netClient,</span><br><span class="line">                   metadata,</span><br><span class="line">                   time,</span><br><span class="line">                   retryBackoffMs,</span><br><span class="line">                   config.getInt(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG),</span><br><span class="line">                   heartbeatIntervalMs); <span class="comment">//Will avoid blocking an extended period of time to prevent heartbeat thread starvation</span></span><br><span class="line">           OffsetResetStrategy offsetResetStrategy = OffsetResetStrategy.valueOf(config.getString(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG).toUpperCase(Locale.ROOT));</span><br><span class="line">           <span class="keyword">this</span>.subscriptions = <span class="keyword">new</span> SubscriptionState(offsetResetStrategy);</span><br><span class="line">           <span class="keyword">this</span>.assignors = config.getConfiguredInstances(</span><br><span class="line">                   ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG,</span><br><span class="line">                   PartitionAssignor.class);</span><br><span class="line"></span><br><span class="line">           <span class="keyword">int</span> maxPollIntervalMs = config.getInt(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG);</span><br><span class="line">           <span class="keyword">int</span> sessionTimeoutMs = config.getInt(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG);</span><br><span class="line">           <span class="comment">// 指定groupId才会构建coordinator。这个coordinator后面会协调消费情况</span></span><br><span class="line">           <span class="keyword">this</span>.coordinator = groupId == <span class="keyword">null</span> ? <span class="keyword">null</span> :</span><br><span class="line">               <span class="keyword">new</span> ConsumerCoordinator(logContext,</span><br><span class="line">                       <span class="keyword">this</span>.client,</span><br><span class="line">                       groupId,</span><br><span class="line">                       maxPollIntervalMs,</span><br><span class="line">                       sessionTimeoutMs,</span><br><span class="line">                       <span class="keyword">new</span> Heartbeat(time, sessionTimeoutMs, heartbeatIntervalMs, maxPollIntervalMs, retryBackoffMs),</span><br><span class="line">                       assignors,</span><br><span class="line">                       <span class="keyword">this</span>.metadata,</span><br><span class="line">                       <span class="keyword">this</span>.subscriptions,</span><br><span class="line">                       metrics,</span><br><span class="line">                       metricGrpPrefix,</span><br><span class="line">                       <span class="keyword">this</span>.time,</span><br><span class="line">                       retryBackoffMs,</span><br><span class="line">                       enableAutoCommit,</span><br><span class="line">                       config.getInt(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG),</span><br><span class="line">                       <span class="keyword">this</span>.interceptors,</span><br><span class="line">                       config.getBoolean(ConsumerConfig.EXCLUDE_INTERNAL_TOPICS_CONFIG),</span><br><span class="line">                       config.getBoolean(ConsumerConfig.LEAVE_GROUP_ON_CLOSE_CONFIG));</span><br><span class="line">           <span class="comment">// 构建获取数据的fetcher</span></span><br><span class="line">           <span class="keyword">this</span>.fetcher = <span class="keyword">new</span> Fetcher&lt;&gt;(</span><br><span class="line">                   logContext,</span><br><span class="line">                   <span class="keyword">this</span>.client,</span><br><span class="line">                   config.getInt(ConsumerConfig.FETCH_MIN_BYTES_CONFIG),</span><br><span class="line">                   config.getInt(ConsumerConfig.FETCH_MAX_BYTES_CONFIG),</span><br><span class="line">                   config.getInt(ConsumerConfig.FETCH_MAX_WAIT_MS_CONFIG),</span><br><span class="line">                   config.getInt(ConsumerConfig.MAX_PARTITION_FETCH_BYTES_CONFIG),</span><br><span class="line">                   config.getInt(ConsumerConfig.MAX_POLL_RECORDS_CONFIG),</span><br><span class="line">                   config.getBoolean(ConsumerConfig.CHECK_CRCS_CONFIG),</span><br><span class="line">                   <span class="keyword">this</span>.keyDeserializer,</span><br><span class="line">                   <span class="keyword">this</span>.valueDeserializer,</span><br><span class="line">                   <span class="keyword">this</span>.metadata,</span><br><span class="line">                   <span class="keyword">this</span>.subscriptions,</span><br><span class="line">                   metrics,</span><br><span class="line">                   metricsRegistry.fetcherMetrics,</span><br><span class="line">                   <span class="keyword">this</span>.time,</span><br><span class="line">                   <span class="keyword">this</span>.retryBackoffMs,</span><br><span class="line">                   <span class="keyword">this</span>.requestTimeoutMs,</span><br><span class="line">                   isolationLevel);</span><br><span class="line"></span><br><span class="line">           config.logUnused();</span><br><span class="line">           AppInfoParser.registerAppInfo(JMX_PREFIX, clientId, metrics);</span><br><span class="line">           log.debug(<span class="string">"Kafka consumer initialized"</span>);</span><br><span class="line">       &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">           <span class="comment">// call close methods if internal objects are already constructed; this is to prevent resource leak. see KAFKA-2121</span></span><br><span class="line">           close(<span class="number">0</span>, <span class="keyword">true</span>);</span><br><span class="line">           <span class="comment">// now propagate the exception</span></span><br><span class="line">           <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">"Failed to construct kafka consumer"</span>, t);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>从这里我们大致了解了KafkaConsumer的构建过程，知道了client-id是由当参数传递给KafkaConsumer，或者是有client按“consumer-序列号”规则生成。<br>而consumer-id是有服务端生成，其过程:</p>
<p>KafkaConsumer实例构建后，会向服务端发起JOIN_GROUP操作kafkaApis<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ApiKeys.JOIN_GROUP;</span><br></pre></td></tr></table></figure></p>
<p>handleJoinGroupRequest=&gt; handleJoinGroup</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">case</span> <span class="title">Some</span><span class="params">(group)</span> </span>=&gt;</span><br><span class="line">  group.inLock &#123;</span><br><span class="line">    <span class="keyword">if</span> ((groupIsOverCapacity(group)</span><br><span class="line">          &amp;&amp; group.has(memberId) &amp;&amp; !group.get(memberId).isAwaitingJoin) <span class="comment">// oversized group, need to shed members that haven't joined yet</span></span><br><span class="line">        || (isUnknownMember &amp;&amp; group.size &gt;= groupConfig.groupMaxSize)) &#123;</span><br><span class="line">      group.remove(memberId)</span><br><span class="line">      responseCallback(joinError(JoinGroupRequest.UNKNOWN_MEMBER_ID, Errors.GROUP_MAX_SIZE_REACHED))</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (isUnknownMember) &#123;</span><br><span class="line">      doUnknownJoinGroup(group, requireKnownMemberId, clientId, clientHost, rebalanceTimeoutMs, sessionTimeoutMs, protocolType, protocols, responseCallback)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      doJoinGroup(group, memberId, clientId, clientHost, rebalanceTimeoutMs, sessionTimeoutMs, protocolType, protocols, responseCallback)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// attempt to complete JoinGroup</span></span><br><span class="line">    <span class="keyword">if</span> (group.is(PreparingRebalance)) &#123;</span><br><span class="line">      joinPurgatory.checkAndComplete(GroupKey(group.groupId))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>第一次请求时服务端没有分配memberId(即consumerId),按isUnknownMember处理</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// doUnknownJoinGroup</span></span><br><span class="line">val newMemberId = clientId + <span class="string">"-"</span> + group.generateMemberIdSuffix</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">def generateMemberIdSuffix = UUID.randomUUID().toString</span><br></pre></td></tr></table></figure>
<h3 id="FlinkKafkaConsumer实现"><a href="#FlinkKafkaConsumer实现" class="headerlink" title="FlinkKafkaConsumer实现"></a>FlinkKafkaConsumer实现</h3><p>Flink的通用kafka-connector部分源码:</p>
<p>FlinkKafkaConsumer</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="title">FlinkKafkaConsumer</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">	List&lt;String&gt; topics,</span></span></span><br><span class="line"><span class="function"><span class="params">	Pattern subscriptionPattern,</span></span></span><br><span class="line"><span class="function"><span class="params">	KafkaDeserializationSchema&lt;T&gt; deserializer,</span></span></span><br><span class="line"><span class="function"><span class="params">	Properties props)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">super</span>(</span><br><span class="line">		topics,</span><br><span class="line">		subscriptionPattern,</span><br><span class="line">		deserializer,</span><br><span class="line">		getLong(</span><br><span class="line">			checkNotNull(props, <span class="string">"props"</span>),</span><br><span class="line">			KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS, PARTITION_DISCOVERY_DISABLED),</span><br><span class="line">		!getBoolean(props, KEY_DISABLE_METRICS, <span class="keyword">false</span>));</span><br><span class="line"></span><br><span class="line">	<span class="keyword">this</span>.properties = props;</span><br><span class="line">	setDeserializer(<span class="keyword">this</span>.properties);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// configure the polling timeout</span></span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		<span class="keyword">if</span> (properties.containsKey(KEY_POLL_TIMEOUT)) &#123;</span><br><span class="line">			<span class="keyword">this</span>.pollTimeout = Long.parseLong(properties.getProperty(KEY_POLL_TIMEOUT));</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="keyword">this</span>.pollTimeout = DEFAULT_POLL_TIMEOUT;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">		<span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Cannot parse poll timeout for '"</span> + KEY_POLL_TIMEOUT + <span class="string">'\''</span>, e);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>connector拉取数据的逻辑见org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">runFetchLoop</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		<span class="keyword">final</span> Handover handover = <span class="keyword">this</span>.handover;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// kick off the actual Kafka consumer</span></span><br><span class="line">		consumerThread.start();</span><br><span class="line"></span><br><span class="line">		<span class="keyword">while</span> (running) &#123;</span><br><span class="line">			<span class="comment">// this blocks until we get the next records</span></span><br><span class="line">			<span class="comment">// it automatically re-throws exceptions encountered in the consumer thread</span></span><br><span class="line">			<span class="keyword">final</span> ConsumerRecords&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; records = handover.pollNext();</span><br><span class="line"></span><br><span class="line">			<span class="comment">// get the records for each topic partition</span></span><br><span class="line">			<span class="keyword">for</span> (KafkaTopicPartitionState&lt;TopicPartition&gt; partition : subscribedPartitionStates()) &#123;</span><br><span class="line">                                <span class="comment">// 这里拉数据</span></span><br><span class="line">				List&lt;ConsumerRecord&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt;&gt; partitionRecords =</span><br><span class="line">					records.records(partition.getKafkaPartitionHandle());</span><br><span class="line"></span><br><span class="line">				<span class="keyword">for</span> (ConsumerRecord&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; record : partitionRecords) &#123;</span><br><span class="line">					<span class="keyword">final</span> T value = deserializer.deserialize(record);</span><br><span class="line"></span><br><span class="line">					<span class="keyword">if</span> (deserializer.isEndOfStream(value)) &#123;</span><br><span class="line">						<span class="comment">// end of stream signaled</span></span><br><span class="line">						running = <span class="keyword">false</span>;</span><br><span class="line">						<span class="keyword">break</span>;</span><br><span class="line">					&#125;</span><br><span class="line"></span><br><span class="line">					<span class="comment">// emit the actual record. this also updates offset state atomically</span></span><br><span class="line">					<span class="comment">// and deals with timestamps and watermark generation</span></span><br><span class="line">					emitRecord(value, partition, record.offset(), record);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">finally</span> &#123;</span><br><span class="line">		<span class="comment">// this signals the consumer thread that no more work is to be done</span></span><br><span class="line">		consumerThread.shutdown();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// on a clean exit, wait for the runner thread</span></span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		consumerThread.join();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">		<span class="comment">// may be the result of a wake-up interruption after an exception.</span></span><br><span class="line">		<span class="comment">// we ignore this here and only restore the interruption state</span></span><br><span class="line">		Thread.currentThread().interrupt();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>org.apache.kafka.clients.consumer.ConsumerRecords从指定partition获取数据</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Get just the records for the given partition</span></span><br><span class="line"><span class="comment"> * 从指定partition获取数据</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> partition The partition to get records for</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> List&lt;ConsumerRecord&lt;K, V&gt;&gt; records(TopicPartition partition) &#123;</span><br><span class="line">    List&lt;ConsumerRecord&lt;K, V&gt;&gt; recs = <span class="keyword">this</span>.records.get(partition);</span><br><span class="line">    <span class="keyword">if</span> (recs == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> Collections.emptyList();</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> Collections.unmodifiableList(recs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在flink中，会通过<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> ConsumerRecords&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; records = handover.pollNext();</span><br></pre></td></tr></table></figure></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">partitionRecords =</span><br><span class="line">					records.records(partition.getKafkaPartitionHandle());</span><br></pre></td></tr></table></figure>
<p>去拉去对应partition的数据。</p>
<p>那么consumer的partition如何重新分配的呢<br>在KafkaComsumerThreader. run的时候会分配</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (newPartitions != <span class="keyword">null</span>) &#123;</span><br><span class="line">    reassignPartitions(newPartitions);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Reestablishes the assigned partitions for the consumer. The reassigned partitions consists of</span></span><br><span class="line"><span class="comment">     * the provided new partitions and whatever partitions was already previously assigned to the</span></span><br><span class="line"><span class="comment">     * consumer.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * &lt;p&gt;The reassignment process is protected against wakeup calls, so that after this method</span></span><br><span class="line"><span class="comment">     * returns, the consumer is either untouched or completely reassigned with the correct offset</span></span><br><span class="line"><span class="comment">     * positions.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * &lt;p&gt;If the consumer was already woken-up prior to a reassignment resulting in an interruption</span></span><br><span class="line"><span class="comment">     * any time during the reassignment, the consumer is guaranteed to roll back as if it was</span></span><br><span class="line"><span class="comment">     * untouched. On the other hand, if there was an attempt to wakeup the consumer during the</span></span><br><span class="line"><span class="comment">     * reassignment, the wakeup call is "buffered" until the reassignment completes.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * &lt;p&gt;This method is exposed for testing purposes.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@VisibleForTesting</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">reassignPartitions</span><span class="params">(List&lt;KafkaTopicPartitionState&lt;T, TopicPartition&gt;&gt; newPartitions)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (newPartitions.size() == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        hasAssignedPartitions = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">boolean</span> reassignmentStarted = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// since the reassignment may introduce several Kafka blocking calls that cannot be</span></span><br><span class="line">        <span class="comment">// interrupted,</span></span><br><span class="line">        <span class="comment">// the consumer needs to be isolated from external wakeup calls in setOffsetsToCommit() and</span></span><br><span class="line">        <span class="comment">// shutdown()</span></span><br><span class="line">        <span class="comment">// until the reassignment is complete.</span></span><br><span class="line">        <span class="keyword">final</span> KafkaConsumer&lt;<span class="keyword">byte</span>[], <span class="keyword">byte</span>[]&gt; consumerTmp;</span><br><span class="line">        <span class="keyword">synchronized</span> (consumerReassignmentLock) &#123;</span><br><span class="line">            consumerTmp = <span class="keyword">this</span>.consumer;</span><br><span class="line">            <span class="keyword">this</span>.consumer = <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> Map&lt;TopicPartition, Long&gt; oldPartitionAssignmentsToPosition = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">for</span> (TopicPartition oldPartition : consumerTmp.assignment()) &#123;</span><br><span class="line">                oldPartitionAssignmentsToPosition.put(</span><br><span class="line">                        oldPartition, consumerTmp.position(oldPartition));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">final</span> List&lt;TopicPartition&gt; newPartitionAssignments =</span><br><span class="line">                    <span class="keyword">new</span> ArrayList&lt;&gt;(</span><br><span class="line">                            newPartitions.size() + oldPartitionAssignmentsToPosition.size());</span><br><span class="line">            newPartitionAssignments.addAll(oldPartitionAssignmentsToPosition.keySet());</span><br><span class="line">            newPartitionAssignments.addAll(convertKafkaPartitions(newPartitions));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// reassign with the new partitions</span></span><br><span class="line">            consumerTmp.assign(newPartitionAssignments);</span><br><span class="line">            reassignmentStarted = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// old partitions should be seeked to their previous position</span></span><br><span class="line">            <span class="keyword">for</span> (Map.Entry&lt;TopicPartition, Long&gt; oldPartitionToPosition :</span><br><span class="line">                    oldPartitionAssignmentsToPosition.entrySet()) &#123;</span><br><span class="line">                consumerTmp.seek(</span><br><span class="line">                        oldPartitionToPosition.getKey(), oldPartitionToPosition.getValue());</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// offsets in the state of new partitions may still be placeholder sentinel values if we</span></span><br><span class="line">            <span class="comment">// are:</span></span><br><span class="line">            <span class="comment">//   (1) starting fresh,</span></span><br><span class="line">            <span class="comment">//   (2) checkpoint / savepoint state we were restored with had not completely</span></span><br><span class="line">            <span class="comment">//       been replaced with actual offset values yet, or</span></span><br><span class="line">            <span class="comment">//   (3) the partition was newly discovered after startup;</span></span><br><span class="line">            <span class="comment">// replace those with actual offsets, according to what the sentinel value represent.</span></span><br><span class="line">            <span class="keyword">for</span> (KafkaTopicPartitionState&lt;T, TopicPartition&gt; newPartitionState : newPartitions) &#123;</span><br><span class="line">                <span class="keyword">if</span> (newPartitionState.getOffset()</span><br><span class="line">                        == KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET) &#123;</span><br><span class="line">                    consumerTmp.seekToBeginning(</span><br><span class="line">                            Collections.singletonList(newPartitionState.getKafkaPartitionHandle()));</span><br><span class="line">                    newPartitionState.setOffset(</span><br><span class="line">                            consumerTmp.position(newPartitionState.getKafkaPartitionHandle()) - <span class="number">1</span>);</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (newPartitionState.getOffset()</span><br><span class="line">                        == KafkaTopicPartitionStateSentinel.LATEST_OFFSET) &#123;</span><br><span class="line">                    consumerTmp.seekToEnd(</span><br><span class="line">                            Collections.singletonList(newPartitionState.getKafkaPartitionHandle()));</span><br><span class="line">                    newPartitionState.setOffset(</span><br><span class="line">                            consumerTmp.position(newPartitionState.getKafkaPartitionHandle()) - <span class="number">1</span>);</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (newPartitionState.getOffset()</span><br><span class="line">                        == KafkaTopicPartitionStateSentinel.GROUP_OFFSET) &#123;</span><br><span class="line">                    <span class="comment">// the KafkaConsumer by default will automatically seek the consumer position</span></span><br><span class="line">                    <span class="comment">// to the committed group offset, so we do not need to do it.</span></span><br><span class="line"></span><br><span class="line">                    newPartitionState.setOffset(</span><br><span class="line">                            consumerTmp.position(newPartitionState.getKafkaPartitionHandle()) - <span class="number">1</span>);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    consumerTmp.seek(</span><br><span class="line">                            newPartitionState.getKafkaPartitionHandle(),</span><br><span class="line">                            newPartitionState.getOffset() + <span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (WakeupException e) &#123;</span><br><span class="line">            <span class="comment">// a WakeupException may be thrown if the consumer was invoked wakeup()</span></span><br><span class="line">            <span class="comment">// before it was isolated for the reassignment. In this case, we abort the</span></span><br><span class="line">            <span class="comment">// reassignment and just re-expose the original consumer.</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">synchronized</span> (consumerReassignmentLock) &#123;</span><br><span class="line">                <span class="keyword">this</span>.consumer = consumerTmp;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// if reassignment had already started and affected the consumer,</span></span><br><span class="line">                <span class="comment">// we do a full roll back so that it is as if it was left untouched</span></span><br><span class="line">                <span class="keyword">if</span> (reassignmentStarted) &#123;</span><br><span class="line">                    <span class="keyword">this</span>.consumer.assign(</span><br><span class="line">                            <span class="keyword">new</span> ArrayList&lt;&gt;(oldPartitionAssignmentsToPosition.keySet()));</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">for</span> (Map.Entry&lt;TopicPartition, Long&gt; oldPartitionToPosition :</span><br><span class="line">                            oldPartitionAssignmentsToPosition.entrySet()) &#123;</span><br><span class="line">                        <span class="keyword">this</span>.consumer.seek(</span><br><span class="line">                                oldPartitionToPosition.getKey(), oldPartitionToPosition.getValue());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// no need to restore the wakeup state in this case,</span></span><br><span class="line">                <span class="comment">// since only the last wakeup call is effective anyways</span></span><br><span class="line">                hasBufferedWakeup = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// re-add all new partitions back to the unassigned partitions queue to be picked up</span></span><br><span class="line">                <span class="comment">// again</span></span><br><span class="line">                <span class="keyword">for</span> (KafkaTopicPartitionState&lt;T, TopicPartition&gt; newPartition : newPartitions) &#123;</span><br><span class="line">                    unassignedPartitionsQueue.add(newPartition);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// this signals the main fetch loop to continue through the loop</span></span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> AbortedReassignmentException();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// reassignment complete; expose the reassigned consumer</span></span><br><span class="line">        <span class="keyword">synchronized</span> (consumerReassignmentLock) &#123;</span><br><span class="line">            <span class="keyword">this</span>.consumer = consumerTmp;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// restore wakeup state for the consumer if necessary</span></span><br><span class="line">            <span class="keyword">if</span> (hasBufferedWakeup) &#123;</span><br><span class="line">                <span class="keyword">this</span>.consumer.wakeup();</span><br><span class="line">                hasBufferedWakeup = <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>一句话总结<br>connector自己实现了FlinkKafkaConsumer,且没有按照kafka的feature实现coordinator以及JOIN_GROUOP的逻辑，导致我们传统认为理所当的值没有正常显示。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>配置相同的group.id消费相同的topic</p>
<p>不管有没有开启checkPoint</p>
<p>两个程序相互隔离，同一条数据，两个程序都可以消费到。</p>
<p>差别在于消费的位置</p>
<p>如果配置startFromLast，都会从最新的 数据开始消费 </p>
<p>如果采用默认配置，第一次消费的时候从上面kafka上的offset开始消费，后面就开始各管各的。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/zh/dev/connectors/kafka.html" target="_blank" rel="noopener">https://ci.apache.org/projects/flink/flink-docs-release-1.11/zh/dev/connectors/kafka.html</a></p>
<p><a href="http://apache-flink.147419.n8.nabble.com/FlinkKafkaConsumer-td6818.html" target="_blank" rel="noopener">http://apache-flink.147419.n8.nabble.com/FlinkKafkaConsumer-td6818.html</a></p>
<p><a href="https://blog.csdn.net/u013128262/article/details/105442182" target="_blank" rel="noopener">https://blog.csdn.net/u013128262/article/details/105442182</a></p>
<p><a href="http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/Flink-kafka-group-question-td8185.html#none" target="_blank" rel="noopener">http://apache-flink-user-mailing-list-archive.2336050.n4.nabble.com/Flink-kafka-group-question-td8185.html#none</a></p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/05/16/flink-消费-kafka-消费组-offset-提交/" rel="next" title="flink 消费 kafka 消费组 offset 提交">
                <i class="fa fa-chevron-left"></i> flink 消费 kafka 消费组 offset 提交
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="https://note.youdao.com/yws/api/personal/file/85E1A31B078749AAA5FBFA9FF57A0FCB?method=download&shareKey=312d566957926c021bfd2bf29d0fb19c#/images/avatar.gif" alt="笑笑">
            
              <p class="site-author-name" itemprop="name">笑笑</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">134</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">15</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
            </nav>
          

          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#问题"><span class="nav-number">1.</span> <span class="nav-text">问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#解答"><span class="nav-number">2.</span> <span class="nav-text">解答</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#注意"><span class="nav-number">3.</span> <span class="nav-text">注意</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#源码分析"><span class="nav-number">4.</span> <span class="nav-text">源码分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#KafkaConsumer实现"><span class="nav-number">5.</span> <span class="nav-text">KafkaConsumer实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#FlinkKafkaConsumer实现"><span class="nav-number">6.</span> <span class="nav-text">FlinkKafkaConsumer实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#总结"><span class="nav-number">7.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Reference"><span class="nav-number">8.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        
<div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">笑笑</span>

  

  
</div>

  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.0.1</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.1"></script>

  <script src="/js/src/motion.js?v=7.0.1"></script>



  
  


  <script src="/js/src/affix.js?v=7.0.1"></script>

  <script src="/js/src/schemes/pisces.js?v=7.0.1"></script>



  
  <script src="/js/src/scrollspy.js?v=7.0.1"></script>
<script src="/js/src/post-details.js?v=7.0.1"></script>



  


  <script src="/js/src/next-boot.js?v=7.0.1"></script>


  

  

  

  


  


  




  

  

  

  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
